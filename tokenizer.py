
from nltk.tokenize.punkt import PunktWordTokenizer
import networkx as nxo

class TextToken:

    def __init__(seltf, ngram):

        self.value = ngram

class ElementToken:  

    def __init__(self, name, attrib):

        self.name = name
        self.attrib = attrib

        # Generate a string consisting of the element name and concatenated attributes (for comparison using the edit distance)
        # Note: the athtributes *must* be order by some arbitrary feature
        self.value = self.name

# The Fragment Entity passed to the Juxta visualization interface
class Fragment:

    def __init__(self, tokens):

        self.value

class Tokenizer:

    def __init__(self):

        pass

    # Construct the parse tree
    # Each element is a node distinct from the 
    def parse(node):

        # Initialize an undirected graph for the tree, setting the root node to the lxml node
        token_tree = nx.Graph()
        token_tree_root = ElementToken(node)

        # For the text of the node, use the PunktWordTokenizer to tokenize the text
        # Ensure that each tokenized n-gram is linked to the lxml token for the tree:
        #    o
        # /     \
        # n-gram n-gram

        text_tokens = map( token_tree_root.children, PunktWordTokenizer().tokenize(text_node) )
        text_token_edges = map(lambda token: (token_tree_root, TextToken(token)), text_tokens )
        token_tree.add_edges_from(text_token_edges)
        
        # If the lxml has no more nodes, return the tree
        if len(node.children) == 0:

            return token_tree

        # ...otherwise, merge the existing tree with the sub-trees generated by recursion
        return nx.compose(token_tree, map(self.parse, node.children))
